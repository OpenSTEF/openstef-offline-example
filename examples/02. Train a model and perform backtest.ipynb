{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a21f1771",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-25T09:02:32.966305Z",
     "start_time": "2021-08-25T09:02:32.962311Z"
    }
   },
   "source": [
    "# Evaluate the performance of model using Backtest Pipeline\n",
    "In this second example notebook, the performance of the model is analysed using ``train_model_and_forecast_back_test``. First, the prediction job is defined, where the properties of the training and forecasting are specified. Thereafter, the backtest is performed using the prediction job and input data (can be found in the 'data' folder). Thereafter, the results are analysed. "
   ]
  },
  {
   "cell_type": "code",
   "id": "066796c6",
   "metadata": {},
   "source": [
    "import pandas as pd\n",
    "from openstef.pipeline.train_create_forecast_backtest import train_model_and_forecast_back_test\n",
    "from openstef.metrics.figure import plot_feature_importance\n",
    "from openstef.data_classes.model_specifications import ModelSpecificationDataClass\n",
    "from openstef.data_classes.prediction_job import PredictionJobDataClass # TODO, import from openstef when availavle\n",
    "from openstef.plotting.load_forecast_plotter import LoadForecastPlotter\n",
    "\n",
    "# Set plotly as the default pandas plotting backend\n",
    "pd.options.plotting.backend = 'plotly'\n",
    "import plotly.io as pio\n",
    "pio.renderers.default = \"plotly_mimetype+notebook\""
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "b443e6ea",
   "metadata": {},
   "source": [
    "## Prepare for training & backtest\n",
    "Before a model can be trained, the specifications and data need to be defined. The specification of the model are defined in the prediction job (pj), where for example the machine learning model, latitude, longtide and forecast horizon are specified. Furthermore, the data has to be retrieved from the csv file containing both load, weather and energy market data. "
   ]
  },
  {
   "cell_type": "code",
   "id": "86ba5377",
   "metadata": {},
   "source": [
    "# Define properties of training/prediction. We call this a 'prediction_job' \n",
    "pj=PredictionJobDataClass(id=287,\n",
    "        model='xgb',\n",
    "        quantiles=[0.10,0.30,0.50,0.70,0.90],\n",
    "        horizon_minutes=48*60,\n",
    "        resolution_minutes=15,\n",
    "        lat = 1, \n",
    "        lon = 1, \n",
    "        train_components=False,\n",
    "        name='TestPrediction',\n",
    "        model_type_group=None, \n",
    "        hyper_params={}, \n",
    "        feature_names=None, \n",
    "        forecast_type=\"demand\", \n",
    "                  )\n",
    "\n",
    "modelspecs = ModelSpecificationDataClass(id=pj['id'])\n",
    "\n",
    "# Load input data\n",
    "input_data = pd.read_csv('data/get_model_input_pid_287.csv', index_col='index', parse_dates=True)\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "b1483ccb",
   "metadata": {},
   "source": [
    "## Perform backtest\n",
    "Below, the backtest is performed using ``train_model_and_forecast_back_test``, which not only outputs the forecast but also the model, train data, validation data and test data. The availability of both the forecast and realised values, enables you to evaluate the results of the model.\n",
    "\n",
    "One of the variables in the ``train_model_and_forecast_back_test`` are the ``training_horizons``. This entails how far into the future, the model has to predict. Thus, a value of 0.25 means predicting 15 minutes into the future, where as 47.0 entails predicting 47 hours ahead."
   ]
  },
  {
   "cell_type": "code",
   "id": "3695e036",
   "metadata": {},
   "source": [
    "# Perform the backtest\n",
    "n_folds = 2\n",
    "\n",
    "forecast, model, train_data, validation_data, test_data = train_model_and_forecast_back_test(\n",
    "    pj,\n",
    "    modelspecs = modelspecs,\n",
    "    input_data = input_data,\n",
    "    training_horizons=[0.25, 47.0],\n",
    "    n_folds=n_folds,\n",
    " )\n",
    "\n",
    "# If n_folds>1, model is a list of models. In that case, only use the first model\n",
    "if n_folds>1:\n",
    "    model=model[0]"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "7080d8aa",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-25T09:12:20.812338Z",
     "start_time": "2021-08-25T09:12:20.808341Z"
    }
   },
   "source": [
    "## Evaluate results\n",
    "Below, the results of the backtest will be evaluated by means of visualisation (plots) and metrics. "
   ]
  },
  {
   "cell_type": "code",
   "id": "4b0c71ae",
   "metadata": {},
   "source": [
    "for horizon in set(forecast.horizon):\n",
    "    data = forecast.loc[forecast.horizon==horizon]\n",
    "\n",
    "    fig = LoadForecastPlotter().plot(\n",
    "      realized=data[\"realised\"],\n",
    "      forecast=data[\"forecast\"],\n",
    "      quantiles=data.filter(regex=\"quantile\")\n",
    "    )\n",
    "    fig.update_layout(dict(title=f'Horizon {horizon}'))\n",
    "    fig.show()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "9e418f36",
   "metadata": {},
   "source": [
    "Evaluate the error of the forecast by subtracting the realised values by the forecasted values. The visualisation can help to analyse the errors."
   ]
  },
  {
   "cell_type": "code",
   "id": "54426833",
   "metadata": {
    "scrolled": false
   },
   "source": [
    "forecast['err']=forecast['realised']-forecast['forecast']\n",
    "forecast['err'].plot()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "e765f5e1",
   "metadata": {},
   "source": [
    "The mean absolute error (mea) gives insight into the scale of the errors. "
   ]
  },
  {
   "cell_type": "code",
   "id": "8e73f034",
   "metadata": {},
   "source": [
    "mea = forecast.pivot_table(index='horizon', values=['err'], aggfunc=lambda x: x.abs().mean())\n",
    "mea.index=mea.index.astype(str)\n",
    "fig = mea.plot(kind='bar')\n",
    "fig.update_layout(dict(title='MAE',\n",
    "                      xaxis=dict(title='horizon'),\n",
    "                      yaxis=dict(title='MAE [MW]')))"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "e28744af",
   "metadata": {},
   "source": [
    "Lastly, it is of interest too look into the importance of the features the model has used to make the forecast. The larger the block in this plot, the higher the importance of the feature for the forecast."
   ]
  },
  {
   "cell_type": "code",
   "id": "e6cb2814",
   "metadata": {},
   "source": [
    "plot_feature_importance(model.feature_importance_dataframe)"
   ],
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
